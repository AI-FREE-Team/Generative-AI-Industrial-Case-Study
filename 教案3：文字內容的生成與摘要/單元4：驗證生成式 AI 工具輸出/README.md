# 單元四、生成式 AI 工具輸出驗證方法

## 1. 前言
為了確保生成式AI產出的內容是滿足一定的規則的（可能是符合公司內部規定、可能是要避免法律上被究責），我們可以參考在許多導入AI自動化機制的企業都會採用的Human-in-the-loop驗證流程，並搭配使用RAG進行語言模型的驗證，確保我們或是使用者都能夠信任機器人提供的服務。

## 2. Human-in-the-loop
"Human in the loop"（HITL）是一種電腦科學和人工智慧（AI）領域的概念，指的是在人工智慧系統中讓人類參與。這種設計目的在克服機器在處理某些任務上的限制。

<div align=center>
<img src="https://github.com/AI-FREE-Team/Generative-AI-Industrial-Case-Study/blob/main/%E6%95%99%E6%A1%883%EF%BC%9A%E6%96%87%E5%AD%97%E5%85%A7%E5%AE%B9%E7%9A%84%E7%94%9F%E6%88%90%E8%88%87%E6%91%98%E8%A6%81/pics/unit4/pic.human-in-the-loop.png" height="600px">
</div>

採用了Human in the loop的服務方案，會有以下四個特色：
* 提高機器學習模型的準確性。
* 更快達到機器學習模型的目標準確度。
* 結合人類和機器智慧以最大限度地提高準確性。
* 透過機器學習協助人工任務以提高效率。

等於說讓最後的檢驗交給人類來做，但是我們還是能在這樣子的框架當中最大程度的讓AI產出內容；如果我們有在這樣子的框架中否決過任何AI的產出，這些範本也都能作為後續優化或是精進模型的樣本，讓AI犯錯的程度與機率隨時間降低。

## 3. 利用 RAG 驗證大型語言模型輸出內容
如果在撰寫文案的過程中，希望GPT等大型語言模型能夠更接地氣的撰寫文案，或是希望在提供回答的時候能夠一併附上自己的參考來源，那麼就可以使用教案一單元三提及的RAG，將相關的外部知識提供給GPT，這樣子GPT等大型語言模型在回答的時候就會一併附上自己回答的參考依據。

我們建議在廣告營銷領域當中的讀者，可以透過RAG的機制加入過去自身團隊發出後獲得正面回響的文案，進一步讓GPT等大型語言模型能夠從一個更接近讀者的角度撰寫文案初稿，讓後續我們的修正時間也獲得改善！