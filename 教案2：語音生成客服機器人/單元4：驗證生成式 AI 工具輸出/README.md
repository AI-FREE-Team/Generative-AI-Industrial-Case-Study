# 單元四、生成式 AI 工具輸出驗證方法

## 1. 前言
to-do

## 2. 以 RAG 交叉驗證大型語言模型輸出內容
我們曾經在**教案一、生成式AI基礎**的**第四單元、生成式AI工具使用須知**當中提及檢索增強生成（Retrieval-Augmented Generatrion，RAG）的技術，其主要的目的是為了解決語言模型的幻覺行為（Hallucination），如果讀者對於這兩個專有名詞的介紹感到陌生，歡迎參考[教案一的內容介紹](https://github.com/AI-FREE-Team/Generative-AI-Industrial-Case-Study/tree/main/%E6%95%99%E6%A1%881%EF%BC%9A%E7%94%9F%E6%88%90%E5%BC%8F%20AI%20%E5%9F%BA%E7%A4%8E/%E5%96%AE%E5%85%833%EF%BC%9A%E7%94%9F%E6%88%90%E5%BC%8F%20AI%20%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8%E9%A0%88%E7%9F%A5)。

### 2.1 減緩幻覺行為的發生
根據單元三實際展示的畫面，我們所聽到的語音助理所產生的回覆（聲音），其實就是根據GPT等大型語言模型（LLM）輸出的文字，然後再利用一定程序的自然語言處理（NLP）技術，規則化/簡化內容後，再利用文字轉語音（Text-to-Speech）的技術才生出來的。

因此如果GPT等大型語言模型（LLM）在輸出的文字當中，有因為幻覺行為的出現而導致不實的資訊產生，則可能造成客戶的不便；而RAG的出現則可以有效緩解此情況。讀者可以把RAG想作是LLM在輸出文字的最後一階段，會再回頭參考我們特地為LLM準備的「正確的」文字資訊，因此LLM會在輸出文字時，再一次根據我們準備的外部資訊調整最終輸出內容。

此舉將有效降低大型語言模型幻覺行為的出現情況。

### 2.2 根據回覆提供參考索引（Reference）
RAG除了可以有效提高大型語言模型（LLM）在輸出文字的時候提供

## 3. 以 ASR 驗證聲音輸出的正確性

